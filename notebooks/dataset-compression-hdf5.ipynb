{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress dataset using HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "import skimage\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing the testset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LZF compression with single dataset per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting.\n",
      "Processed 50 images. (ips: 1.25 / ETA: 7.43 min)\n",
      "Processed 100 images. (ips: 1.21 / ETA: 7.68 min)\n",
      "Processed 150 images. (ips: 1.22 / ETA: 7.64 min)\n",
      "Processed 200 images. (ips: 1.22 / ETA: 7.65 min)\n",
      "Processed 250 images. (ips: 1.21 / ETA: 7.72 min)\n",
      "Processed 300 images. (ips: 1.21 / ETA: 7.68 min)\n",
      "Processed 350 images. (ips: 1.22 / ETA: 7.66 min)\n",
      "Processed 400 images. (ips: 1.22 / ETA: 7.64 min)\n",
      "Processed 450 images. (ips: 1.21 / ETA: 7.70 min)\n",
      "Processed 500 images. (ips: 1.20 / ETA: 7.78 min)\n",
      "Processed 550 images. (ips: 1.20 / ETA: 7.76 min)\n",
      "Finished. Took 7.76 minutes.\n"
     ]
    }
   ],
   "source": [
    "df_test = pandas.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "images_test = []\n",
    "\n",
    "print(\"Starting.\")\n",
    "tstart = time.time()\n",
    "with h5py.File(\"./data/test.hdf5\", \"w\") as f:\n",
    "    for i,item in df_test.iterrows():\n",
    "        imid = item['ID']\n",
    "        imshape = (item['ImageHeight'], item['ImageWidth'], 4)\n",
    "        #imroot = os.path.join(\"./data/test\", imid)\n",
    "        #imstems = (\"_red.png\", \"_blue.png\", \"_yellow.png\", \"_green.png\")\n",
    "        #paths = [imroot+imstem for imstem in imstems]\n",
    "        #image = [skimage.io.imread(path) for path in paths]\n",
    "        #image = numpy.dstack(image)\n",
    "        #images_test.append(image)\n",
    "        f.create_dataset(\n",
    "                    name=imid,\n",
    "                    data=images[i],\n",
    "                    shape=imshape,\n",
    "                    maxshape=imshape,\n",
    "                    compression=\"lzf\"\n",
    "                   )\n",
    "        if (i+1)%50 == 0:\n",
    "            ips = (i+1)/(time.time()-tstart)\n",
    "            eta = len(df_test)/ips - (len(df_test)-i-1)/ips\n",
    "            print(f\"Processed {i+1} images. (ips: {ips:.2f} / ETA: {eta/60:.2f} min)\")\n",
    "            \n",
    "print(f\"Finished. Took {(time.time()-tstart)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing the Trainset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LZF compression with single dataset per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting.\n",
      "Processed 250 images. (ips: 0.71 / ETA: 507.28 min)\n",
      "Processed 500 images. (ips: 0.65 / ETA: 561.17 min)\n",
      "Processed 750 images. (ips: 0.63 / ETA: 582.80 min)\n",
      "Processed 1000 images. (ips: 0.62 / ETA: 601.51 min)\n",
      "Processed 1250 images. (ips: 0.61 / ETA: 614.65 min)\n"
     ]
    }
   ],
   "source": [
    "df_train = pandas.read_csv(\"./data/train.csv\")\n",
    "images_train = []\n",
    "\n",
    "print(\"Starting.\")\n",
    "tstart = time.time()\n",
    "with h5py.File(\"./data/train.hdf5\", \"w\") as f:\n",
    "    for i,item in df_train.iterrows():\n",
    "        imid = item['ID']\n",
    "        imroot = os.path.join(\"./data/train\", imid)\n",
    "        imstems = (\"_red.png\", \"_blue.png\", \"_yellow.png\", \"_green.png\")\n",
    "        paths = [imroot+imstem for imstem in imstems]\n",
    "        image = [skimage.io.imread(path) for path in paths]\n",
    "        image = numpy.dstack(image)\n",
    "        images_train.append(image)\n",
    "        imshape = image.shape\n",
    "        f.create_dataset(\n",
    "                    name=imid,\n",
    "                    data=image,\n",
    "                    shape=imshape,\n",
    "                    maxshape=imshape,\n",
    "                    compression=\"lzf\"\n",
    "                   )\n",
    "        if (i+1)%250 == 0:\n",
    "            ips = (i+1)/(time.time()-tstart)\n",
    "            eta = len(df_train)/ips - (len(df_test)-i-1)/ips\n",
    "            print(f\"Processed {i+1} images. (ips: {ips:.2f} / ETA: {eta/60:.2f} min)\")\n",
    "            \n",
    "print(f\"Finished. Took {(time.time()-tstart)/60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21806"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not do: LZF compression with ImageDimension pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_1728 = [image for image in images if image.shape[0] == 1728]\n",
    "images_2048 = [image for image in images if image.shape[0] == 2048]\n",
    "images_3072 = [image for image in images if image.shape[0] == 3072]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_1728 = numpy.stack(images_1728)\n",
    "images_2048 = numpy.stack(images_2048)\n",
    "images_3072 = numpy.stack(images_3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting.\n",
      "1728px finished. Took 0.49 minutes. (ips: 2.30)\n",
      "2048px finished. Took 6.76 minutes. (ips: 1.31)\n",
      "3072px finished. Took 7.60 minutes. (ips: 1.23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting.\")\n",
    "tstart = time.time()\n",
    "with h5py.File(\"./data/test_pool.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\n",
    "        name='1728px',\n",
    "        data=images_1728,\n",
    "        shape=images_1728.shape,\n",
    "        maxshape=images_1728.shape,\n",
    "        compression=\"lzf\",\n",
    "       )\n",
    "    ips = images_1728.shape[0]/(time.time()-tstart)\n",
    "    print(f\"1728px finished. Took {(time.time()-tstart)/60:.2f} minutes. (ips: {ips:.2f})\")\n",
    "    f.create_dataset(\n",
    "        name='2048px',\n",
    "        data=images_2048,\n",
    "        shape=images_2048.shape,\n",
    "        maxshape=images_2048.shape,\n",
    "        compression=\"lzf\"\n",
    "       )\n",
    "    ips = (images_1728.shape[0] + images_2048.shape[0])/(time.time()-tstart)\n",
    "    print(f\"2048px finished. Took {(time.time()-tstart)/60:.2f} minutes. (ips: {ips:.2f})\")\n",
    "    f.create_dataset(\n",
    "        name='3072px',\n",
    "        data=images_3072,\n",
    "        shape=images_3072.shape,\n",
    "        maxshape=images_3072.shape,\n",
    "        compression=\"lzf\"\n",
    "       )\n",
    "    ips = (images_1728.shape[0] + images_2048.shape[0] + images_3072.shape[0])/(time.time()-tstart)\n",
    "    print(f\"3072px finished. Took {(time.time()-tstart)/60:.2f} minutes. (ips: {ips:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pandas.read_csv(\"./data/train.csv\")\n",
    "\n",
    "images_train = []\n",
    "for i,item in df_train.iterrows():\n",
    "    imid = item['ID']\n",
    "    imshape = (item['ImageHeight'], item['ImageWidth'], 4)\n",
    "    imroot = os.path.join(\"./data/train\", imid)\n",
    "    imstems = (\"_red.png\", \"_blue.png\", \"_yellow.png\", \"_green.png\")\n",
    "    paths = [imroot+imstem for imstem in imstems]\n",
    "    image = [skimage.io.imread(path) for path in paths]\n",
    "    image = numpy.dstack(image)\n",
    "    images_train.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_1728 = [image for image in images_train if image.shape[0] == 1728]\n",
    "images_2048 = [image for image in images_train if image.shape[0] == 2048]\n",
    "images_3072 = [image for image in images_train if image.shape[0] == 3072]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_1728 = numpy.stack(images_1728)\n",
    "images_2048 = numpy.stack(images_2048)\n",
    "images_3072 = numpy.stack(images_3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting.\")\n",
    "tstart = time.time()\n",
    "with h5py.File(\"./data/train_pool.hdf5\", \"w\") as f:\n",
    "    f.create_dataset(\n",
    "        name='1728px',\n",
    "        data=images_1728,\n",
    "        shape=images_1728.shape,\n",
    "        maxshape=images_1728.shape,\n",
    "        compression=\"lzf\",\n",
    "       )\n",
    "    ips = images_1728.shape[0]/(time.time()-tstart)\n",
    "    print(f\"1728px finished. Took {(time.time()-tstart)/60:.2f} minutes. (ips: {ips:.2f})\")\n",
    "    f.create_dataset(\n",
    "        name='2048px',\n",
    "        data=images_2048,\n",
    "        shape=images_2048.shape,\n",
    "        maxshape=images_2048.shape,\n",
    "        compression=\"lzf\"\n",
    "       )\n",
    "    ips = (images_1728.shape[0] + images_2048.shape[0])/(time.time()-tstart)\n",
    "    print(f\"2048px finished. Took {(time.time()-tstart)/60:.2f} minutes. (ips: {ips:.2f})\")\n",
    "    f.create_dataset(\n",
    "        name='3072px',\n",
    "        data=images_3072,\n",
    "        shape=images_3072.shape,\n",
    "        maxshape=images_3072.shape,\n",
    "        compression=\"lzf\"\n",
    "       )\n",
    "    ips = (images_1728.shape[0] + images_2048.shape[0] + images_3072.shape[0])/(time.time()-tstart)\n",
    "    print(f\"3072px finished. Took {(time.time()-tstart)/60:.2f} minutes. (ips: {ips:.2f})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpa-cpu-env",
   "language": "python",
   "name": "hpa-cpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
